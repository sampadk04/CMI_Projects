{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Transfer Learning for Sentiment Analysis"]},{"cell_type":"markdown","metadata":{},"source":["# 0. Imports"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2023-04-29T13:03:57.914014Z","iopub.status.busy":"2023-04-29T13:03:57.913519Z","iopub.status.idle":"2023-04-29T13:04:02.686038Z","shell.execute_reply":"2023-04-29T13:04:02.685006Z","shell.execute_reply.started":"2023-04-29T13:03:57.913973Z"},"trusted":true},"outputs":[],"source":["import os, pickle\n","\n","# for keeping track of loops\n","from tqdm import tqdm\n","\n","# basic libraries\n","import numpy as np\n","import pandas as pd\n","\n","# import pytorch\n","import torch\n","import torch.nn as nn\n","\n","# import pytorch modules\n","from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n","\n","# imports from transformers\n","import transformers\n","from transformers import AutoModel, BertTokenizerFast\n","\n","# sklearn modules\n","from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n","from sklearn.model_selection import train_test_split\n","from sklearn.utils.class_weight import compute_class_weight\n","\n","# plotting libraries\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","%matplotlib inline"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-04-29T13:04:02.688585Z","iopub.status.busy":"2023-04-29T13:04:02.688079Z","iopub.status.idle":"2023-04-29T13:04:02.696214Z","shell.execute_reply":"2023-04-29T13:04:02.694687Z","shell.execute_reply.started":"2023-04-29T13:04:02.688554Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["cuda\n"]}],"source":["# setting the device to \"mps\" instead of default \"cpu\"\n","# device = torch.device(\"mps\" if torch.backends.mps.is_available else \"cpu\")\n","device = torch.device(\"cuda\" if torch.cuda.is_available else \"cpu\")\n","\n","\n","print(device)"]},{"cell_type":"markdown","metadata":{},"source":["# 1. Preparing Data"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2023-04-29T13:04:07.239590Z","iopub.status.busy":"2023-04-29T13:04:07.239217Z","iopub.status.idle":"2023-04-29T13:04:07.250012Z","shell.execute_reply":"2023-04-29T13:04:07.248936Z","shell.execute_reply.started":"2023-04-29T13:04:07.239555Z"},"trusted":true},"outputs":[{"data":{"text/plain":["'/kaggle/input/sentiment-analysis-dataset'"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["raw_data_dir = '/kaggle/input/sentiment-analysis-dataset'\n","raw_data_dir"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2023-04-29T13:04:07.781130Z","iopub.status.busy":"2023-04-29T13:04:07.780745Z","iopub.status.idle":"2023-04-29T13:04:08.038824Z","shell.execute_reply":"2023-04-29T13:04:08.037736Z","shell.execute_reply.started":"2023-04-29T13:04:07.781097Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>textID</th>\n","      <th>text</th>\n","      <th>selected_text</th>\n","      <th>sentiment</th>\n","      <th>Time of Tweet</th>\n","      <th>Age of User</th>\n","      <th>Country</th>\n","      <th>Population -2020</th>\n","      <th>Land Area (Km²)</th>\n","      <th>Density (P/Km²)</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>cb774db0d1</td>\n","      <td>I`d have responded, if I were going</td>\n","      <td>I`d have responded, if I were going</td>\n","      <td>neutral</td>\n","      <td>morning</td>\n","      <td>0-20</td>\n","      <td>Afghanistan</td>\n","      <td>38928346</td>\n","      <td>652860.0</td>\n","      <td>60</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>549e992a42</td>\n","      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n","      <td>Sooo SAD</td>\n","      <td>negative</td>\n","      <td>noon</td>\n","      <td>21-30</td>\n","      <td>Albania</td>\n","      <td>2877797</td>\n","      <td>27400.0</td>\n","      <td>105</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>088c60f138</td>\n","      <td>my boss is bullying me...</td>\n","      <td>bullying me</td>\n","      <td>negative</td>\n","      <td>night</td>\n","      <td>31-45</td>\n","      <td>Algeria</td>\n","      <td>43851044</td>\n","      <td>2381740.0</td>\n","      <td>18</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>9642c003ef</td>\n","      <td>what interview! leave me alone</td>\n","      <td>leave me alone</td>\n","      <td>negative</td>\n","      <td>morning</td>\n","      <td>46-60</td>\n","      <td>Andorra</td>\n","      <td>77265</td>\n","      <td>470.0</td>\n","      <td>164</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>358bd9e861</td>\n","      <td>Sons of ****, why couldn`t they put them on t...</td>\n","      <td>Sons of ****,</td>\n","      <td>negative</td>\n","      <td>noon</td>\n","      <td>60-70</td>\n","      <td>Angola</td>\n","      <td>32866272</td>\n","      <td>1246700.0</td>\n","      <td>26</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       textID                                               text  \\\n","0  cb774db0d1                I`d have responded, if I were going   \n","1  549e992a42      Sooo SAD I will miss you here in San Diego!!!   \n","2  088c60f138                          my boss is bullying me...   \n","3  9642c003ef                     what interview! leave me alone   \n","4  358bd9e861   Sons of ****, why couldn`t they put them on t...   \n","\n","                         selected_text sentiment Time of Tweet Age of User  \\\n","0  I`d have responded, if I were going   neutral       morning        0-20   \n","1                             Sooo SAD  negative          noon       21-30   \n","2                          bullying me  negative         night       31-45   \n","3                       leave me alone  negative       morning       46-60   \n","4                        Sons of ****,  negative          noon       60-70   \n","\n","       Country  Population -2020  Land Area (Km²)  Density (P/Km²)  \n","0  Afghanistan          38928346         652860.0               60  \n","1      Albania           2877797          27400.0              105  \n","2      Algeria          43851044        2381740.0               18  \n","3      Andorra             77265            470.0              164  \n","4       Angola          32866272        1246700.0               26  "]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["df_train = pd.read_csv(os.path.join(raw_data_dir, 'train.csv'), encoding= 'unicode_escape')\n","df_test = pd.read_csv(os.path.join(raw_data_dir, 'test.csv'), encoding= 'unicode_escape')\n","\n","df_train.head()"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2023-04-29T13:04:08.042045Z","iopub.status.busy":"2023-04-29T13:04:08.040654Z","iopub.status.idle":"2023-04-29T13:04:08.069959Z","shell.execute_reply":"2023-04-29T13:04:08.068861Z","shell.execute_reply.started":"2023-04-29T13:04:08.042004Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 27481 entries, 0 to 27480\n","Data columns (total 10 columns):\n"," #   Column            Non-Null Count  Dtype  \n","---  ------            --------------  -----  \n"," 0   textID            27481 non-null  object \n"," 1   text              27480 non-null  object \n"," 2   selected_text     27480 non-null  object \n"," 3   sentiment         27481 non-null  object \n"," 4   Time of Tweet     27481 non-null  object \n"," 5   Age of User       27481 non-null  object \n"," 6   Country           27481 non-null  object \n"," 7   Population -2020  27481 non-null  int64  \n"," 8   Land Area (Km²)   27481 non-null  float64\n"," 9   Density (P/Km²)   27481 non-null  int64  \n","dtypes: float64(1), int64(2), object(7)\n","memory usage: 2.1+ MB\n"]}],"source":["# check out column info for train\n","df_train.info()"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2023-04-29T13:04:09.109026Z","iopub.status.busy":"2023-04-29T13:04:09.108640Z","iopub.status.idle":"2023-04-29T13:04:09.123965Z","shell.execute_reply":"2023-04-29T13:04:09.122803Z","shell.execute_reply.started":"2023-04-29T13:04:09.108985Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 4815 entries, 0 to 4814\n","Data columns (total 9 columns):\n"," #   Column            Non-Null Count  Dtype  \n","---  ------            --------------  -----  \n"," 0   textID            3534 non-null   object \n"," 1   text              3534 non-null   object \n"," 2   sentiment         3534 non-null   object \n"," 3   Time of Tweet     3534 non-null   object \n"," 4   Age of User       3534 non-null   object \n"," 5   Country           3534 non-null   object \n"," 6   Population -2020  3534 non-null   float64\n"," 7   Land Area (Km²)   3534 non-null   float64\n"," 8   Density (P/Km²)   3534 non-null   float64\n","dtypes: float64(3), object(6)\n","memory usage: 338.7+ KB\n"]}],"source":["# check out column info for test\n","df_test.info()"]},{"cell_type":"markdown","metadata":{},"source":["The test data has the `selected_text` column missing. So, we will be using the `text` column for sentiment analysis."]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2023-04-29T13:04:09.473597Z","iopub.status.busy":"2023-04-29T13:04:09.472897Z","iopub.status.idle":"2023-04-29T13:04:09.495677Z","shell.execute_reply":"2023-04-29T13:04:09.494579Z","shell.execute_reply.started":"2023-04-29T13:04:09.473560Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Train shape: (27480, 2)\n","Test shape: (3534, 2)\n"]}],"source":["df_train.dropna(subset=['text'], inplace=True)\n","df_test.dropna(subset=['text'], inplace=True)\n","\n","# select the columns we need\n","df_train = df_train[['text', 'sentiment']]\n","df_test = df_test[['text', 'sentiment']]\n","\n","# print the shape info for the dataframes\n","print(f\"Train shape: {df_train.shape}\")\n","print(f\"Test shape: {df_test.shape}\")"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2023-04-29T13:04:09.928998Z","iopub.status.busy":"2023-04-29T13:04:09.928618Z","iopub.status.idle":"2023-04-29T13:04:09.941155Z","shell.execute_reply":"2023-04-29T13:04:09.939947Z","shell.execute_reply.started":"2023-04-29T13:04:09.928964Z"},"trusted":true},"outputs":[{"data":{"text/plain":["neutral     0.404549\n","positive    0.312300\n","negative    0.283151\n","Name: sentiment, dtype: float64"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["# we check the class distribution for the train set\n","df_train['sentiment'].value_counts(normalize=True)"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2023-04-29T13:04:10.120987Z","iopub.status.busy":"2023-04-29T13:04:10.120313Z","iopub.status.idle":"2023-04-29T13:04:10.131886Z","shell.execute_reply":"2023-04-29T13:04:10.130857Z","shell.execute_reply.started":"2023-04-29T13:04:10.120943Z"},"trusted":true},"outputs":[{"data":{"text/plain":["neutral     0.404641\n","positive    0.312111\n","negative    0.283248\n","Name: sentiment, dtype: float64"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["# we check the class distribution for the test set\n","df_test['sentiment'].value_counts(normalize=True)"]},{"cell_type":"markdown","metadata":{},"source":["Since, they are identically distributed, we can use the same data loader for both the tasks."]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2023-04-29T13:04:11.705652Z","iopub.status.busy":"2023-04-29T13:04:11.704733Z","iopub.status.idle":"2023-04-29T13:04:11.711007Z","shell.execute_reply":"2023-04-29T13:04:11.709724Z","shell.execute_reply.started":"2023-04-29T13:04:11.705618Z"},"trusted":true},"outputs":[],"source":["# we create a dictionary that maps the labels to integers\n","label2int = {'negative': 0, 'neutral': 1, 'positive': 2}\n","\n","# we create a dictionary that maps the integers back to labels\n","int2label = {v: k for k, v in label2int.items()}"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2023-04-29T13:04:12.076440Z","iopub.status.busy":"2023-04-29T13:04:12.076152Z","iopub.status.idle":"2023-04-29T13:04:12.092007Z","shell.execute_reply":"2023-04-29T13:04:12.090860Z","shell.execute_reply.started":"2023-04-29T13:04:12.076412Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>sentiment</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>I`d have responded, if I were going</td>\n","      <td>neutral</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n","      <td>negative</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>my boss is bullying me...</td>\n","      <td>negative</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>what interview! leave me alone</td>\n","      <td>negative</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Sons of ****, why couldn`t they put them on t...</td>\n","      <td>negative</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                text sentiment  label\n","0                I`d have responded, if I were going   neutral      1\n","1      Sooo SAD I will miss you here in San Diego!!!  negative      0\n","2                          my boss is bullying me...  negative      0\n","3                     what interview! leave me alone  negative      0\n","4   Sons of ****, why couldn`t they put them on t...  negative      0"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["# we create a new column called \"label\" which maps the text labels to integers using the dictionary we created above\n","df_train['label'] = df_train['sentiment'].map(label2int)\n","df_test['label'] = df_test['sentiment'].map(label2int)\n","\n","# we check the head of the train dataframe\n","df_train.head()"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2023-04-29T13:04:12.220941Z","iopub.status.busy":"2023-04-29T13:04:12.220447Z","iopub.status.idle":"2023-04-29T13:04:12.234379Z","shell.execute_reply":"2023-04-29T13:04:12.233220Z","shell.execute_reply.started":"2023-04-29T13:04:12.220913Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Train shape: (23358,)\n","Validation shape: (4122,)\n","Test shape: (3534,)\n"]}],"source":["# we first split the train set into train and validation sets\n","\n","train_text, val_text, train_labels, val_labels = train_test_split(df_train['text'], df_train['label'], test_size=0.15, random_state=42)\n","\n","# set the test text, label pairs\n","test_text, test_labels = df_test['text'], df_test['label']\n","\n","# print the shape of the train, val, and test sets\n","print(f\"Train shape: {train_text.shape}\")\n","print(f\"Validation shape: {val_text.shape}\")\n","print(f\"Test shape: {test_text.shape}\")"]},{"cell_type":"markdown","metadata":{},"source":["# 2. BERT Tokenization"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-04-29T13:04:12.781582Z","iopub.status.busy":"2023-04-29T13:04:12.780580Z","iopub.status.idle":"2023-04-29T13:04:19.856950Z","shell.execute_reply":"2023-04-29T13:04:19.855794Z","shell.execute_reply.started":"2023-04-29T13:04:12.781508Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"39b998ba2d2646129482777de1329491","version_major":2,"version_minor":0},"text/plain":["Downloading (…)lve/main/config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0ce30ca00521429ba705ff50e9522816","version_major":2,"version_minor":0},"text/plain":["Downloading pytorch_model.bin:   0%|          | 0.00/440M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"30957c8712cd4959896c6c0fd4b398cd","version_major":2,"version_minor":0},"text/plain":["Downloading (…)okenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6e4165c7a5d744a1b8b5210a5c0d223e","version_major":2,"version_minor":0},"text/plain":["Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"89c385a958834b4194e08fd76ec315da","version_major":2,"version_minor":0},"text/plain":["Downloading (…)/main/tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["# import BERT-base pretrained model\n","bert = AutoModel.from_pretrained('bert-base-uncased', return_dict=False)\n","\n","# Load the BERT tokenizer\n","tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2023-04-29T13:04:55.092330Z","iopub.status.busy":"2023-04-29T13:04:55.091872Z","iopub.status.idle":"2023-04-29T13:04:55.105704Z","shell.execute_reply":"2023-04-29T13:04:55.104231Z","shell.execute_reply.started":"2023-04-29T13:04:55.092288Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["{'input_ids': [[101, 2023, 2003, 1037, 7099, 3793, 2000, 2022, 19204, 3550, 102, 0, 0], [101, 2057, 2097, 2022, 2478, 14324, 1011, 2918, 19204, 17629, 2005, 2023, 102]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}\n"]}],"source":["# check the tokenizer of sample texts\n","sample_text = [\"this is a sample text to be tokenized\", \"we will be using bert-base tokenizer for this\"]\n","\n","# encode the sample text\n","sample_text_id = tokenizer.batch_encode_plus(sample_text, padding=True, return_token_type_ids=False)\n","\n","# print the encoded text\n","print(sample_text_id)"]},{"cell_type":"markdown","metadata":{},"source":["This simultaneously stores the `input_ids` and `attention_mask` for the input sentence. The `input_ids` are the token ids of the input sentence and the `attention_mask` is a binary mask indicating the position of the padded indices so that the model does not attend to them."]},{"cell_type":"markdown","metadata":{},"source":["## 2.1 Tokenization"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2023-04-29T13:04:57.215362Z","iopub.status.busy":"2023-04-29T13:04:57.214666Z","iopub.status.idle":"2023-04-29T13:04:57.561748Z","shell.execute_reply":"2023-04-29T13:04:57.560732Z","shell.execute_reply.started":"2023-04-29T13:04:57.215323Z"},"trusted":true},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 800x500 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["# extract the length of all the texts in the train set\n","train_text_len = [len(text.split()) for text in train_text]\n","\n","# plot the distribution of the train text length\n","plt.figure(figsize=(8, 5))\n","sns.histplot(train_text_len)\n","plt.title('The distribution of the train text length')\n","plt.xlabel('Text length')\n","plt.ylabel('Frequency')\n","plt.show()"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2023-04-29T13:04:58.571981Z","iopub.status.busy":"2023-04-29T13:04:58.570832Z","iopub.status.idle":"2023-04-29T13:04:58.604190Z","shell.execute_reply":"2023-04-29T13:04:58.603026Z","shell.execute_reply.started":"2023-04-29T13:04:58.571931Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Maximum length of the texts in train_text: 33\n"]}],"source":["# find the maximum length of the texts in train_text\n","max_len = max([len(text.split()) for text in train_text])\n","print(f\"Maximum length of the texts in train_text: {max_len}\")"]},{"cell_type":"markdown","metadata":{},"source":["Based on the above plot, we can observe that the maximum length of the input sentence is less than `35`. So, we will be using a maximum length of `35` for padding the input sentence."]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2023-04-29T13:04:59.676437Z","iopub.status.busy":"2023-04-29T13:04:59.675270Z","iopub.status.idle":"2023-04-29T13:05:01.937435Z","shell.execute_reply":"2023-04-29T13:05:01.936352Z","shell.execute_reply.started":"2023-04-29T13:04:59.676396Z"},"trusted":true},"outputs":[],"source":["# set the maximum length of the sequences\n","max_seq_len = 35\n","\n","# tokenize and encode sequences in the training set\n","tokens_train = tokenizer.batch_encode_plus(\n","    train_text.tolist(),\n","    max_length=max_seq_len,\n","    padding=True,\n","    truncation=True,\n","    return_token_type_ids=False\n",")\n","\n","# tokenize and encode sequences in the validation set\n","tokens_val = tokenizer.batch_encode_plus(\n","    val_text.tolist(),\n","    max_length=max_seq_len,\n","    padding=True,\n","    truncation=True,\n","    return_token_type_ids=False\n",")\n","\n","# tokenize and encode sequences in the test set\n","tokens_test = tokenizer.batch_encode_plus(\n","    test_text.tolist(),\n","    max_length=max_seq_len,\n","    padding=True,\n","    truncation=True,\n","    return_token_type_ids=False\n",")"]},{"cell_type":"markdown","metadata":{},"source":["## 2.2 Convert Integer Sequences to Tensors"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2023-04-29T13:05:01.941833Z","iopub.status.busy":"2023-04-29T13:05:01.941506Z","iopub.status.idle":"2023-04-29T13:05:02.087306Z","shell.execute_reply":"2023-04-29T13:05:02.086325Z","shell.execute_reply.started":"2023-04-29T13:05:01.941798Z"},"trusted":true},"outputs":[],"source":["# for train set\n","train_seq = torch.tensor(tokens_train['input_ids'])\n","train_mask = torch.tensor(tokens_train['attention_mask'])\n","train_y = torch.tensor(train_labels.tolist())\n","\n","# for validation set\n","val_seq = torch.tensor(tokens_val['input_ids'])\n","val_mask = torch.tensor(tokens_val['attention_mask'])\n","val_y = torch.tensor(val_labels.tolist())\n","\n","# for test set\n","test_seq = torch.tensor(tokens_test['input_ids'])\n","test_mask = torch.tensor(tokens_test['attention_mask'])\n","test_y = torch.tensor(test_labels.tolist())"]},{"cell_type":"markdown","metadata":{},"source":["## 2.3 Create DataLoaders"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2023-04-29T13:05:03.489111Z","iopub.status.busy":"2023-04-29T13:05:03.488169Z","iopub.status.idle":"2023-04-29T13:05:03.495940Z","shell.execute_reply":"2023-04-29T13:05:03.494841Z","shell.execute_reply.started":"2023-04-29T13:05:03.489060Z"},"trusted":true},"outputs":[],"source":["# define a batch size\n","batch_size = 32\n","\n","## for train set\n","# wrap tensors\n","train_data = TensorDataset(train_seq, train_mask, train_y)\n","\n","# sampler for sampling the data during training\n","train_sampler = RandomSampler(train_data)\n","\n","# dataLoader for train set\n","train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n","\n","## for validation set\n","# wrap tensors\n","val_data = TensorDataset(val_seq, val_mask, val_y)\n","\n","# sampler for sampling the data during training\n","val_sampler = SequentialSampler(val_data)\n","\n","# dataLoader for validation set\n","val_dataloader = DataLoader(val_data, sampler = val_sampler, batch_size=batch_size)"]},{"cell_type":"markdown","metadata":{},"source":["# 3. Fine-Tuning BERT"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2023-04-29T13:05:04.887319Z","iopub.status.busy":"2023-04-29T13:05:04.886632Z","iopub.status.idle":"2023-04-29T13:05:04.896595Z","shell.execute_reply":"2023-04-29T13:05:04.895513Z","shell.execute_reply.started":"2023-04-29T13:05:04.887280Z"},"trusted":true},"outputs":[],"source":["# freeze all the parameters\n","for param in bert.parameters():\n","    param.requires_grad = False\n","\n","# define the model\n","class BERT_Arch(nn.Module):\n","        def __init__(self, bert):\n","            super(BERT_Arch, self).__init__()\n","            self.bert = bert\n","            # dropout layer\n","            self.dropout = nn.Dropout(0.1)\n","            # relu activation function\n","            self.relu = nn.ReLU()\n","            # dense layer 1\n","            self.fc1 = nn.Linear(768, 512)\n","            # dense layer 2 (Output layer)\n","            self.fc2 = nn.Linear(512, 3)\n","            # softmax activation function\n","            self.softmax = nn.LogSoftmax(dim=1)\n","    \n","        # define the forward pass\n","        def forward(self, sent_id, mask):\n","            # pass the inputs to the model\n","            _, cls_hs = self.bert(sent_id, attention_mask=mask)\n","            x = self.fc1(cls_hs)\n","            x = self.relu(x)\n","            x = self.dropout(x)\n","            # output layer\n","            x = self.fc2(x)\n","            # apply softmax activation\n","            x = self.softmax(x)\n","            return x"]},{"cell_type":"code","execution_count":40,"metadata":{"execution":{"iopub.execute_input":"2023-04-29T13:20:45.808354Z","iopub.status.busy":"2023-04-29T13:20:45.807647Z","iopub.status.idle":"2023-04-29T13:20:45.824829Z","shell.execute_reply":"2023-04-29T13:20:45.823813Z","shell.execute_reply.started":"2023-04-29T13:20:45.808314Z"},"trusted":true},"outputs":[],"source":["# pass the pre-trained BERT to our define architecture\n","model = BERT_Arch(bert)\n","\n","# push the model to GPU\n","model = model.to(device)\n","\n","# define the optimizer\n","optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3)"]},{"cell_type":"markdown","metadata":{},"source":["## 3.1 Find Class Weights"]},{"cell_type":"code","execution_count":41,"metadata":{"execution":{"iopub.execute_input":"2023-04-29T13:20:46.214873Z","iopub.status.busy":"2023-04-29T13:20:46.214537Z","iopub.status.idle":"2023-04-29T13:20:46.227086Z","shell.execute_reply":"2023-04-29T13:20:46.225840Z","shell.execute_reply.started":"2023-04-29T13:20:46.214843Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["{0: 1.1773778920308484, 1: 0.8254001908194636, 2: 1.0648249452954048}\n"]}],"source":["#compute the class weights\n","class_weights = compute_class_weight(\n","                                        class_weight = \"balanced\",\n","                                        classes = np.unique(train_labels),\n","                                        y = train_labels\n",")\n","\n","class_weights_dict = dict(zip(np.unique(train_labels), class_weights))\n","print(class_weights_dict)"]},{"cell_type":"code","execution_count":42,"metadata":{"execution":{"iopub.execute_input":"2023-04-29T13:20:46.491461Z","iopub.status.busy":"2023-04-29T13:20:46.491089Z","iopub.status.idle":"2023-04-29T13:20:46.498293Z","shell.execute_reply":"2023-04-29T13:20:46.497068Z","shell.execute_reply.started":"2023-04-29T13:20:46.491426Z"},"trusted":true},"outputs":[],"source":["# convert class weights to tensor\n","weights= torch.tensor(class_weights, dtype=torch.float)\n","weights = weights.to(device)\n","\n","# loss function\n","cross_entropy = nn.NLLLoss(weight=weights)"]},{"cell_type":"markdown","metadata":{},"source":["## 3.2 Define the `train` and `evaluate` functions"]},{"cell_type":"code","execution_count":43,"metadata":{"execution":{"iopub.execute_input":"2023-04-29T13:20:46.896395Z","iopub.status.busy":"2023-04-29T13:20:46.895696Z","iopub.status.idle":"2023-04-29T13:20:46.906657Z","shell.execute_reply":"2023-04-29T13:20:46.905531Z","shell.execute_reply.started":"2023-04-29T13:20:46.896349Z"},"trusted":true},"outputs":[],"source":["# function to train the model\n","def train():\n","  \n","  model.train()\n","\n","  total_loss, total_accuracy = 0.0, 0.0\n","  \n","  # empty list to save model predictions\n","  total_preds=[]\n","  \n","  # iterate over batches\n","  for step,batch in enumerate(train_dataloader):\n","    \n","    # progress update after every 200 batches.\n","    if step % 200 == 0 and not step == 0:\n","      print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(train_dataloader)))\n","\n","    # push the batch to gpu\n","    batch = [r.to(device) for r in batch]\n"," \n","    sent_id, mask, labels = batch\n","\n","    # clear previously calculated gradients \n","    model.zero_grad()        \n","\n","    # get model predictions for the current batch\n","    preds = model(sent_id, mask)\n","\n","    # compute the loss between actual and predicted values\n","    loss = cross_entropy(preds, labels)\n","\n","    # add on to the total loss\n","    total_loss = total_loss + loss.item()\n","\n","    # backward pass to calculate the gradients\n","    loss.backward()\n","\n","    # clip the the gradients to 1.0. It helps in preventing the exploding gradient problem\n","    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","\n","    # update parameters\n","    optimizer.step()\n","\n","    # model predictions are stored on GPU. So, push it to CPU\n","    preds=preds.detach().cpu().numpy()\n","\n","    # append the model predictions\n","    total_preds.append(preds)\n","\n","  # compute the training loss of the epoch\n","  avg_loss = total_loss / len(train_dataloader)\n","  \n","  # predictions are in the form of (no. of batches, size of batch, no. of classes).\n","  # reshape the predictions in form of (number of samples, no. of classes)\n","  total_preds  = np.concatenate(total_preds, axis=0)\n","\n","  #returns the loss and predictions\n","  return avg_loss, total_preds"]},{"cell_type":"code","execution_count":44,"metadata":{"execution":{"iopub.execute_input":"2023-04-29T13:20:47.421547Z","iopub.status.busy":"2023-04-29T13:20:47.420724Z","iopub.status.idle":"2023-04-29T13:20:47.435674Z","shell.execute_reply":"2023-04-29T13:20:47.433936Z","shell.execute_reply.started":"2023-04-29T13:20:47.421502Z"},"trusted":true},"outputs":[],"source":["# function for evaluating the model\n","def evaluate():\n","  \n","  print(\"\\nEvaluating...\")\n","  \n","  # deactivate dropout layers\n","  model.eval()\n","\n","  total_loss, total_accuracy = 0, 0\n","  \n","  # empty list to save the model predictions\n","  total_preds = []\n","\n","  # iterate over batches\n","  for step,batch in enumerate(val_dataloader):\n","    \n","    # Progress update every 50 batches.\n","    if step % 50 == 0 and not step == 0:\n","            \n","      # Report progress.\n","      print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(val_dataloader)))\n","\n","    # push the batch to gpu\n","    batch = [t.to(device) for t in batch]\n","\n","    sent_id, mask, labels = batch\n","\n","    # deactivate autograd\n","    with torch.no_grad():\n","      \n","      # model predictions\n","      preds = model(sent_id, mask)\n","\n","      # compute the validation loss between actual and predicted values\n","      loss = cross_entropy(preds,labels)\n","\n","      total_loss = total_loss + loss.item()\n","\n","      preds = preds.detach().cpu().numpy()\n","\n","      total_preds.append(preds)\n","\n","  # compute the validation loss of the epoch\n","  avg_loss = total_loss / len(val_dataloader) \n","\n","  # reshape the predictions in form of (number of samples, no. of classes)\n","  total_preds  = np.concatenate(total_preds, axis=0)\n","\n","  return avg_loss, total_preds"]},{"cell_type":"markdown","metadata":{},"source":["## 3.3 Train the Model"]},{"cell_type":"code","execution_count":45,"metadata":{"execution":{"iopub.execute_input":"2023-04-29T13:20:50.415362Z","iopub.status.busy":"2023-04-29T13:20:50.414987Z","iopub.status.idle":"2023-04-29T13:20:51.388255Z","shell.execute_reply":"2023-04-29T13:20:51.387069Z","shell.execute_reply.started":"2023-04-29T13:20:50.415327Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","mkdir: cannot create directory ‘/kaggle/working/models’: File exists\n"]}],"source":["# create a directory named models, to store the saved models\n","models_dir = os.path.join(os.getcwd(), 'models')\n","! mkdir $models_dir"]},{"cell_type":"code","execution_count":46,"metadata":{"execution":{"iopub.execute_input":"2023-04-29T13:20:54.544049Z","iopub.status.busy":"2023-04-29T13:20:54.543501Z","iopub.status.idle":"2023-04-29T13:46:56.992673Z","shell.execute_reply":"2023-04-29T13:46:56.991547Z","shell.execute_reply.started":"2023-04-29T13:20:54.543999Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["\n"," Epoch 1 / 50\n","  Batch   200  of    730.\n","  Batch   400  of    730.\n","  Batch   600  of    730.\n","\n","Evaluating...\n","  Batch    50  of    129.\n","  Batch   100  of    129.\n","\n","Training Loss: 1.009\n","Validation Loss: 0.945\n","\n"," Epoch 2 / 50\n","  Batch   200  of    730.\n","  Batch   400  of    730.\n","  Batch   600  of    730.\n","\n","Evaluating...\n","  Batch    50  of    129.\n","  Batch   100  of    129.\n","\n","Training Loss: 0.932\n","Validation Loss: 0.912\n","\n"," Epoch 3 / 50\n","  Batch   200  of    730.\n","  Batch   400  of    730.\n","  Batch   600  of    730.\n","\n","Evaluating...\n","  Batch    50  of    129.\n","  Batch   100  of    129.\n","\n","Training Loss: 0.919\n","Validation Loss: 0.872\n","\n"," Epoch 4 / 50\n","  Batch   200  of    730.\n","  Batch   400  of    730.\n","  Batch   600  of    730.\n","\n","Evaluating...\n","  Batch    50  of    129.\n","  Batch   100  of    129.\n","\n","Training Loss: 0.901\n","Validation Loss: 0.913\n","\n"," Epoch 5 / 50\n","  Batch   200  of    730.\n","  Batch   400  of    730.\n","  Batch   600  of    730.\n","\n","Evaluating...\n","  Batch    50  of    129.\n","  Batch   100  of    129.\n","\n","Training Loss: 0.893\n","Validation Loss: 0.827\n","\n"," Epoch 6 / 50\n","  Batch   200  of    730.\n","  Batch   400  of    730.\n","  Batch   600  of    730.\n","\n","Evaluating...\n","  Batch    50  of    129.\n","  Batch   100  of    129.\n","\n","Training Loss: 0.884\n","Validation Loss: 0.813\n","\n"," Epoch 7 / 50\n","  Batch   200  of    730.\n","  Batch   400  of    730.\n","  Batch   600  of    730.\n","\n","Evaluating...\n","  Batch    50  of    129.\n","  Batch   100  of    129.\n","\n","Training Loss: 0.874\n","Validation Loss: 0.870\n","\n"," Epoch 8 / 50\n","  Batch   200  of    730.\n","  Batch   400  of    730.\n","  Batch   600  of    730.\n","\n","Evaluating...\n","  Batch    50  of    129.\n","  Batch   100  of    129.\n","\n","Training Loss: 0.879\n","Validation Loss: 0.862\n","\n"," Epoch 9 / 50\n","  Batch   200  of    730.\n","  Batch   400  of    730.\n","  Batch   600  of    730.\n","\n","Evaluating...\n","  Batch    50  of    129.\n","  Batch   100  of    129.\n","\n","Training Loss: 0.866\n","Validation Loss: 0.832\n","\n"," Epoch 10 / 50\n","  Batch   200  of    730.\n","  Batch   400  of    730.\n","  Batch   600  of    730.\n","\n","Evaluating...\n","  Batch    50  of    129.\n","  Batch   100  of    129.\n","\n","Training Loss: 0.865\n","Validation Loss: 0.802\n","\n"," Epoch 11 / 50\n","  Batch   200  of    730.\n","  Batch   400  of    730.\n","  Batch   600  of    730.\n","\n","Evaluating...\n","  Batch    50  of    129.\n","  Batch   100  of    129.\n","\n","Training Loss: 0.863\n","Validation Loss: 0.873\n","\n"," Epoch 12 / 50\n","  Batch   200  of    730.\n","  Batch   400  of    730.\n","  Batch   600  of    730.\n","\n","Evaluating...\n","  Batch    50  of    129.\n","  Batch   100  of    129.\n","\n","Training Loss: 0.859\n","Validation Loss: 0.794\n","\n"," Epoch 13 / 50\n","  Batch   200  of    730.\n","  Batch   400  of    730.\n","  Batch   600  of    730.\n","\n","Evaluating...\n","  Batch    50  of    129.\n","  Batch   100  of    129.\n","\n","Training Loss: 0.861\n","Validation Loss: 0.790\n","\n"," Epoch 14 / 50\n","  Batch   200  of    730.\n","  Batch   400  of    730.\n","  Batch   600  of    730.\n","\n","Evaluating...\n","  Batch    50  of    129.\n","  Batch   100  of    129.\n","\n","Training Loss: 0.859\n","Validation Loss: 0.810\n","\n"," Epoch 15 / 50\n","  Batch   200  of    730.\n","  Batch   400  of    730.\n","  Batch   600  of    730.\n","\n","Evaluating...\n","  Batch    50  of    129.\n","  Batch   100  of    129.\n","\n","Training Loss: 0.848\n","Validation Loss: 0.804\n","\n"," Epoch 16 / 50\n","  Batch   200  of    730.\n","  Batch   400  of    730.\n","  Batch   600  of    730.\n","\n","Evaluating...\n","  Batch    50  of    129.\n","  Batch   100  of    129.\n","\n","Training Loss: 0.850\n","Validation Loss: 0.895\n","\n"," Epoch 17 / 50\n","  Batch   200  of    730.\n","  Batch   400  of    730.\n","  Batch   600  of    730.\n","\n","Evaluating...\n","  Batch    50  of    129.\n","  Batch   100  of    129.\n","\n","Training Loss: 0.847\n","Validation Loss: 0.824\n","\n"," Epoch 18 / 50\n","  Batch   200  of    730.\n","  Batch   400  of    730.\n","  Batch   600  of    730.\n","\n","Evaluating...\n","  Batch    50  of    129.\n","  Batch   100  of    129.\n","\n","Training Loss: 0.855\n","Validation Loss: 0.790\n","\n"," Epoch 19 / 50\n","  Batch   200  of    730.\n","  Batch   400  of    730.\n","  Batch   600  of    730.\n","\n","Evaluating...\n","  Batch    50  of    129.\n","  Batch   100  of    129.\n","\n","Training Loss: 0.851\n","Validation Loss: 0.847\n","\n"," Epoch 20 / 50\n","  Batch   200  of    730.\n","  Batch   400  of    730.\n","  Batch   600  of    730.\n","\n","Evaluating...\n","  Batch    50  of    129.\n","  Batch   100  of    129.\n","\n","Training Loss: 0.848\n","Validation Loss: 0.789\n","\n"," Epoch 21 / 50\n","  Batch   200  of    730.\n","  Batch   400  of    730.\n","  Batch   600  of    730.\n","\n","Evaluating...\n","  Batch    50  of    129.\n","  Batch   100  of    129.\n","\n","Training Loss: 0.849\n","Validation Loss: 0.804\n","\n"," Epoch 22 / 50\n","  Batch   200  of    730.\n","  Batch   400  of    730.\n","  Batch   600  of    730.\n","\n","Evaluating...\n","  Batch    50  of    129.\n","  Batch   100  of    129.\n","\n","Training Loss: 0.844\n","Validation Loss: 0.791\n","\n"," Epoch 23 / 50\n","  Batch   200  of    730.\n","  Batch   400  of    730.\n","  Batch   600  of    730.\n","\n","Evaluating...\n","  Batch    50  of    129.\n","  Batch   100  of    129.\n","\n","Training Loss: 0.844\n","Validation Loss: 0.824\n","\n"," Epoch 24 / 50\n","  Batch   200  of    730.\n","  Batch   400  of    730.\n","  Batch   600  of    730.\n","\n","Evaluating...\n","  Batch    50  of    129.\n","  Batch   100  of    129.\n","\n","Training Loss: 0.845\n","Validation Loss: 0.780\n","\n"," Epoch 25 / 50\n","  Batch   200  of    730.\n","  Batch   400  of    730.\n","  Batch   600  of    730.\n","\n","Evaluating...\n","  Batch    50  of    129.\n","  Batch   100  of    129.\n","\n","Training Loss: 0.846\n","Validation Loss: 0.784\n","\n"," Epoch 26 / 50\n","  Batch   200  of    730.\n","  Batch   400  of    730.\n","  Batch   600  of    730.\n","\n","Evaluating...\n","  Batch    50  of    129.\n","  Batch   100  of    129.\n","\n","Training Loss: 0.838\n","Validation Loss: 0.784\n","\n"," Epoch 27 / 50\n","  Batch   200  of    730.\n","  Batch   400  of    730.\n","  Batch   600  of    730.\n","\n","Evaluating...\n","  Batch    50  of    129.\n","  Batch   100  of    129.\n","\n","Training Loss: 0.844\n","Validation Loss: 0.803\n","\n"," Epoch 28 / 50\n","  Batch   200  of    730.\n","  Batch   400  of    730.\n","  Batch   600  of    730.\n","\n","Evaluating...\n","  Batch    50  of    129.\n","  Batch   100  of    129.\n","\n","Training Loss: 0.840\n","Validation Loss: 0.806\n","\n"," Epoch 29 / 50\n","  Batch   200  of    730.\n","  Batch   400  of    730.\n","  Batch   600  of    730.\n","\n","Evaluating...\n","  Batch    50  of    129.\n","  Batch   100  of    129.\n","\n","Training Loss: 0.838\n","Validation Loss: 0.863\n","\n"," Epoch 30 / 50\n","  Batch   200  of    730.\n","  Batch   400  of    730.\n","  Batch   600  of    730.\n","\n","Evaluating...\n","  Batch    50  of    129.\n","  Batch   100  of    129.\n","\n","Training Loss: 0.839\n","Validation Loss: 0.787\n","\n"," Epoch 31 / 50\n","  Batch   200  of    730.\n","  Batch   400  of    730.\n","  Batch   600  of    730.\n","\n","Evaluating...\n","  Batch    50  of    129.\n","  Batch   100  of    129.\n","\n","Training Loss: 0.835\n","Validation Loss: 0.787\n","\n"," Epoch 32 / 50\n","  Batch   200  of    730.\n","  Batch   400  of    730.\n","  Batch   600  of    730.\n","\n","Evaluating...\n","  Batch    50  of    129.\n","  Batch   100  of    129.\n","\n","Training Loss: 0.835\n","Validation Loss: 0.795\n","\n"," Epoch 33 / 50\n","  Batch   200  of    730.\n","  Batch   400  of    730.\n","  Batch   600  of    730.\n","\n","Evaluating...\n","  Batch    50  of    129.\n","  Batch   100  of    129.\n","\n","Training Loss: 0.840\n","Validation Loss: 0.818\n","\n"," Epoch 34 / 50\n","  Batch   200  of    730.\n","  Batch   400  of    730.\n","  Batch   600  of    730.\n","\n","Evaluating...\n","  Batch    50  of    129.\n","  Batch   100  of    129.\n","\n","Training Loss: 0.836\n","Validation Loss: 0.785\n","\n"," Epoch 35 / 50\n","  Batch   200  of    730.\n","  Batch   400  of    730.\n","  Batch   600  of    730.\n","\n","Evaluating...\n","  Batch    50  of    129.\n","  Batch   100  of    129.\n","\n","Training Loss: 0.843\n","Validation Loss: 0.789\n","\n"," Epoch 36 / 50\n","  Batch   200  of    730.\n","  Batch   400  of    730.\n","  Batch   600  of    730.\n","\n","Evaluating...\n","  Batch    50  of    129.\n","  Batch   100  of    129.\n","\n","Training Loss: 0.837\n","Validation Loss: 0.793\n","\n"," Epoch 37 / 50\n","  Batch   200  of    730.\n","  Batch   400  of    730.\n","  Batch   600  of    730.\n","\n","Evaluating...\n","  Batch    50  of    129.\n","  Batch   100  of    129.\n","\n","Training Loss: 0.835\n","Validation Loss: 0.785\n","\n"," Epoch 38 / 50\n","  Batch   200  of    730.\n","  Batch   400  of    730.\n","  Batch   600  of    730.\n","\n","Evaluating...\n","  Batch    50  of    129.\n","  Batch   100  of    129.\n","\n","Training Loss: 0.836\n","Validation Loss: 0.799\n","\n"," Epoch 39 / 50\n","  Batch   200  of    730.\n","  Batch   400  of    730.\n","  Batch   600  of    730.\n","\n","Evaluating...\n","  Batch    50  of    129.\n","  Batch   100  of    129.\n","\n","Training Loss: 0.841\n","Validation Loss: 0.772\n","\n"," Epoch 40 / 50\n","  Batch   200  of    730.\n","  Batch   400  of    730.\n","  Batch   600  of    730.\n","\n","Evaluating...\n","  Batch    50  of    129.\n","  Batch   100  of    129.\n","\n","Training Loss: 0.835\n","Validation Loss: 0.798\n","\n"," Epoch 41 / 50\n","  Batch   200  of    730.\n","  Batch   400  of    730.\n","  Batch   600  of    730.\n","\n","Evaluating...\n","  Batch    50  of    129.\n","  Batch   100  of    129.\n","\n","Training Loss: 0.836\n","Validation Loss: 0.801\n","\n"," Epoch 42 / 50\n","  Batch   200  of    730.\n","  Batch   400  of    730.\n","  Batch   600  of    730.\n","\n","Evaluating...\n","  Batch    50  of    129.\n","  Batch   100  of    129.\n","\n","Training Loss: 0.830\n","Validation Loss: 0.877\n","\n"," Epoch 43 / 50\n","  Batch   200  of    730.\n","  Batch   400  of    730.\n","  Batch   600  of    730.\n","\n","Evaluating...\n","  Batch    50  of    129.\n","  Batch   100  of    129.\n","\n","Training Loss: 0.835\n","Validation Loss: 0.791\n","\n"," Epoch 44 / 50\n","  Batch   200  of    730.\n","  Batch   400  of    730.\n","  Batch   600  of    730.\n","\n","Evaluating...\n","  Batch    50  of    129.\n","  Batch   100  of    129.\n","\n","Training Loss: 0.830\n","Validation Loss: 0.771\n","\n"," Epoch 45 / 50\n","  Batch   200  of    730.\n","  Batch   400  of    730.\n","  Batch   600  of    730.\n","\n","Evaluating...\n","  Batch    50  of    129.\n","  Batch   100  of    129.\n","\n","Training Loss: 0.828\n","Validation Loss: 0.787\n","\n"," Epoch 46 / 50\n","  Batch   200  of    730.\n","  Batch   400  of    730.\n","  Batch   600  of    730.\n","\n","Evaluating...\n","  Batch    50  of    129.\n","  Batch   100  of    129.\n","\n","Training Loss: 0.831\n","Validation Loss: 0.787\n","\n"," Epoch 47 / 50\n","  Batch   200  of    730.\n","  Batch   400  of    730.\n","  Batch   600  of    730.\n","\n","Evaluating...\n","  Batch    50  of    129.\n","  Batch   100  of    129.\n","\n","Training Loss: 0.828\n","Validation Loss: 0.785\n","\n"," Epoch 48 / 50\n","  Batch   200  of    730.\n","  Batch   400  of    730.\n","  Batch   600  of    730.\n","\n","Evaluating...\n","  Batch    50  of    129.\n","  Batch   100  of    129.\n","\n","Training Loss: 0.831\n","Validation Loss: 0.789\n","\n"," Epoch 49 / 50\n","  Batch   200  of    730.\n","  Batch   400  of    730.\n","  Batch   600  of    730.\n","\n","Evaluating...\n","  Batch    50  of    129.\n","  Batch   100  of    129.\n","\n","Training Loss: 0.834\n","Validation Loss: 0.777\n","\n"," Epoch 50 / 50\n","  Batch   200  of    730.\n","  Batch   400  of    730.\n","  Batch   600  of    730.\n","\n","Evaluating...\n","  Batch    50  of    129.\n","  Batch   100  of    129.\n","\n","Training Loss: 0.827\n","Validation Loss: 0.774\n"]}],"source":["# number of training epochs\n","epochs = 50\n","\n","# set initial loss to infinite\n","best_valid_loss = float('inf')\n","\n","# empty lists to store training and validation loss of each epoch\n","train_losses=[]\n","valid_losses=[]\n","\n","#for each epoch\n","for epoch in range(epochs):\n","     \n","    print('\\n Epoch {:} / {:}'.format(epoch + 1, epochs))\n","    \n","    #train model\n","    train_loss, _ = train()\n","    \n","    #evaluate model\n","    valid_loss, _ = evaluate()\n","    \n","    #save the best model\n","    if valid_loss < best_valid_loss:\n","        best_valid_loss = valid_loss\n","        torch.save(model.state_dict(), os.path.join('models', 'saved_weights.pt'))\n","    \n","    # append training and validation loss\n","    train_losses.append(train_loss)\n","    valid_losses.append(valid_loss)\n","    \n","    print(f'\\nTraining Loss: {train_loss:.3f}')\n","    print(f'Validation Loss: {valid_loss:.3f}')"]},{"cell_type":"code","execution_count":47,"metadata":{"execution":{"iopub.execute_input":"2023-04-29T13:47:02.683354Z","iopub.status.busy":"2023-04-29T13:47:02.682978Z","iopub.status.idle":"2023-04-29T13:47:02.939457Z","shell.execute_reply":"2023-04-29T13:47:02.938175Z","shell.execute_reply.started":"2023-04-29T13:47:02.683318Z"},"trusted":true},"outputs":[{"data":{"text/plain":["<All keys matched successfully>"]},"execution_count":47,"metadata":{},"output_type":"execute_result"}],"source":["# load weights of best model\n","best_model_path = os.path.join('models', 'saved_weights.pt')\n","model.load_state_dict(torch.load(best_model_path))"]},{"cell_type":"markdown","metadata":{},"source":["# 4. Evaluation on the Test Data"]},{"cell_type":"code","execution_count":48,"metadata":{"execution":{"iopub.execute_input":"2023-04-29T13:47:08.235227Z","iopub.status.busy":"2023-04-29T13:47:08.233971Z","iopub.status.idle":"2023-04-29T13:47:11.300748Z","shell.execute_reply":"2023-04-29T13:47:11.299657Z","shell.execute_reply.started":"2023-04-29T13:47:08.235181Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.58      0.77      0.66      1001\n","           1       0.70      0.45      0.55      1430\n","           2       0.64      0.74      0.69      1103\n","\n","    accuracy                           0.63      3534\n","   macro avg       0.64      0.66      0.63      3534\n","weighted avg       0.65      0.63      0.62      3534\n","\n"]}],"source":["# get predictions for test data\n","with torch.no_grad():\n","    preds = model(test_seq.to(device), test_mask.to(device))\n","    preds = preds.detach().cpu().numpy()\n","\n","preds = np.argmax(preds, axis = 1)\n","\n","print(classification_report(test_y, preds))"]},{"cell_type":"code","execution_count":49,"metadata":{"execution":{"iopub.execute_input":"2023-04-29T13:47:17.244598Z","iopub.status.busy":"2023-04-29T13:47:17.243513Z","iopub.status.idle":"2023-04-29T13:47:17.269006Z","shell.execute_reply":"2023-04-29T13:47:17.268064Z","shell.execute_reply.started":"2023-04-29T13:47:17.244553Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th>col_0</th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","    </tr>\n","    <tr>\n","      <th>row_0</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>773</td>\n","      <td>117</td>\n","      <td>111</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>441</td>\n","      <td>645</td>\n","      <td>344</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>125</td>\n","      <td>159</td>\n","      <td>819</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["col_0    0    1    2\n","row_0               \n","0      773  117  111\n","1      441  645  344\n","2      125  159  819"]},"execution_count":49,"metadata":{},"output_type":"execute_result"}],"source":["# confusion matrix\n","pd.crosstab(test_y, preds)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.6"}},"nbformat":4,"nbformat_minor":4}
